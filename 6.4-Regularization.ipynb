{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8207ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89438eca",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "#### Overfitting\n",
    "\n",
    "When a model has high variance, it is said to *overfit* the data.  Overfitting is an issue because the model will not *generalize* well to new data.\n",
    "\n",
    "#### Parameter Shrinkage\n",
    "\n",
    "Shrinking the parameters $\\theta = (\\beta_0, \\beta_1,...,\\beta_n)^T$ of a linear model close (or equal) to $0$ can significantly reduce model variance and decrease overfitting.\n",
    "\n",
    "*Regularization* is a technique that can accomplish *parameter shrinkage*.  In general, SGD with a regularization term has the form\n",
    "\n",
    "$$L_{GEN} = \\frac{1}{N}\\sum_{i=1}^NL(y_i, \\hat{y}_i)+\\alpha R(\\theta) $$ \n",
    "\n",
    "where $\\alpha \\geq 0$ is a *hyperparameter* and $R(\\theta) \\geq 0$ is the regularization function.  Note that $R$ is a function of the parameters $\\theta$ and that there are different parameter estimates $\\hat{\\beta}_i$ for each value of $\\alpha$. \n",
    "\n",
    "The two most common regularization functions are:\n",
    "\n",
    "+ Ridge: $R(\\theta) = \\sum_{i=0}^{k}\\beta_i^2$, where $k = $len$(\\theta)$.\n",
    "    + This is also called the $l_2$ penalty, since it uses the $l_2=||\\theta||_2^2$ (or Euclidean) norm.\n",
    "\n",
    "+ Lasso: $R(\\theta) = \\sum_{i=0}^{k}|\\beta_i|$, where $k = $len$(\\theta)$.\n",
    "    + This is also called the $l_1$ penalty, since it uses the $l_1=||\\theta||_1^2$ (or Manhattan) norm.\n",
    "\n",
    "So, how does the addition of the term $\\alpha R(\\theta)$ shrink the parameters $\\hat{\\beta}_i$ close to $0$?\n",
    "\n",
    "We are trying to find values of $\\theta = (\\beta_0, \\beta_1,...,\\beta_n)^T$ that make $L_{GEN}$ as small as possible.  However, it is possible to find a value of $\\theta$ that makes $L_{GEN}$ small where $\\beta_0, \\beta_1,...,\\beta_n$ are big.  The *shrinkage penalty* $\\alpha R(\\theta)$ penalizes this situation by making \n",
    "\n",
    "$$L_{GEN} = \\frac{1}{N}\\sum_{i=1}^NL(y_i, \\hat{y}_i)+\\alpha R(\\theta) $$\n",
    "\n",
    "bigger.  Thus, the values $\\beta_0, \\beta_1,...,\\beta_n$ that make\n",
    "\n",
    "$$L_{GEN} = \\frac{1}{N}\\sum_{i=1}^NL(y_i, \\hat{y}_i)+\\alpha R(\\theta) $$\n",
    "\n",
    "as small as possible will make $\\frac{1}{N}\\sum_{i=1}^NL(y_i, \\hat{y}_i)$ small and make $\\alpha R(\\theta)$ small.\n",
    "\n",
    "##### Example 1\n",
    "\n",
    "We train a mult-logistic regression classifier for the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ab7857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = pd.DataFrame(iris.data, columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "data['Label'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a42a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  Label\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0\n",
       "3           4.6          3.1           1.5          0.2      0\n",
       "4           5.0          3.6           1.4          0.2      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f41324",
   "metadata": {},
   "source": [
    "##### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d78bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c91d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "data[cols_to_scale] = scaler.fit_transform(data[cols_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e403655",
   "metadata": {},
   "source": [
    "##### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8a236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].to_numpy()\n",
    "y = data.iloc[:, -1:].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e143b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.25, random_state=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05e0ac",
   "metadata": {},
   "source": [
    "We play around with different values for $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d791a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=0.01, loss=&#x27;log_loss&#x27;, penalty=&#x27;l1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.01, loss=&#x27;log_loss&#x27;, penalty=&#x27;l1&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(alpha=0.01, loss='log_loss', penalty='l1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SGDClassifier(loss = 'log_loss', penalty = 'l1', alpha = 0.01)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fca15f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "(y_pred == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d36fe",
   "metadata": {},
   "source": [
    "$\\Box$\n",
    "\n",
    "#### Hyperparameter Selection\n",
    "\n",
    "As we saw in Example 1, different choices for the penalty and alpha gave differing performance by our model.\n",
    "\n",
    "We could guess and check to find semi-optimal values for our hyperparameters $R(\\theta)$ and $\\alpha$, but a better way is to use *cross validation*.  k-fold cross validation is discussed [here](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).  \n",
    "\n",
    "There are many cross validation techniques that can be used to select optimum hyperparameters, but in this class we will only look at *grid-search cross validation*.  The documentation is given [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV).\n",
    "\n",
    "##### Example 2\n",
    "\n",
    "We use Sci-Kit Learn's GridSearchCV class to select the best values to use for the penalty and alpha hyperparameters.\n",
    "\n",
    "First, we use a dictionary to specify what values to use for which hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc943a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty':('l1', 'l2'), 'alpha':[0.0001, 0.001, 0.01, 0.1, 1.0, 2.0, 3.0, 4.0, 5.0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78288420",
   "metadata": {},
   "source": [
    "Next, we specify our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27c2975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(loss = 'log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "854ffb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d995bf6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SGDClassifier(loss=&#x27;log_loss&#x27;),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1.0, 2.0, 3.0, 4.0,\n",
       "                                   5.0],\n",
       "                         &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SGDClassifier(loss=&#x27;log_loss&#x27;),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1.0, 2.0, 3.0, 4.0,\n",
       "                                   5.0],\n",
       "                         &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log_loss&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SGDClassifier(loss='log_loss'),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 2.0, 3.0, 4.0,\n",
       "                                   5.0],\n",
       "                         'penalty': ('l1', 'l2')})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5671fed",
   "metadata": {},
   "source": [
    "The *cv_results_* attribute gives many interesting results from the cross validation process as a dictionary.\n",
    "\n",
    "We can pass this info to a Pandas DataFrame to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41f0bda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909881</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909881</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007878</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909881</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.909881</td>\n",
       "      <td>0.050519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006272</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.927668</td>\n",
       "      <td>0.046593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.892095</td>\n",
       "      <td>0.047226</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.900791</td>\n",
       "      <td>0.045504</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.883004</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.330830</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.006331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.873518</td>\n",
       "      <td>0.073618</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 2.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.339921</td>\n",
       "      <td>0.029045</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.003120</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 2.0, 'penalty': 'l2'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.837549</td>\n",
       "      <td>0.093971</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 3.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.330830</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 3.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828063</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 4.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.312648</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 4.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.811067</td>\n",
       "      <td>0.079176</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 5.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.021843</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 5.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.802372</td>\n",
       "      <td>0.063574</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.005984      0.004554         0.001583        0.001104      0.0001   \n",
       "1        0.004178      0.002431         0.000903        0.000801      0.0001   \n",
       "2        0.007878      0.007110         0.000000        0.000000       0.001   \n",
       "3        0.003169      0.006337         0.000000        0.000000       0.001   \n",
       "4        0.006272      0.007681         0.000000        0.000000        0.01   \n",
       "5        0.003124      0.006249         0.000000        0.000000        0.01   \n",
       "6        0.004297      0.006361         0.003141        0.006282         0.1   \n",
       "7        0.000100      0.000199         0.003305        0.006610         0.1   \n",
       "8        0.003168      0.006336         0.000000        0.000000         1.0   \n",
       "9        0.003165      0.006331         0.000000        0.000000         1.0   \n",
       "10       0.000000      0.000000         0.000000        0.000000         2.0   \n",
       "11       0.003120      0.006241         0.000000        0.000000         2.0   \n",
       "12       0.003125      0.006251         0.000000        0.000000         3.0   \n",
       "13       0.004021      0.004962         0.000000        0.000000         3.0   \n",
       "14       0.006266      0.007675         0.000000        0.000000         4.0   \n",
       "15       0.003124      0.006248         0.000000        0.000000         4.0   \n",
       "16       0.003143      0.006286         0.000000        0.000000         5.0   \n",
       "17       0.003144      0.006288         0.000000        0.000000         5.0   \n",
       "\n",
       "   param_penalty                              params  split0_test_score  \\\n",
       "0             l1  {'alpha': 0.0001, 'penalty': 'l1'}           0.956522   \n",
       "1             l2  {'alpha': 0.0001, 'penalty': 'l2'}           0.956522   \n",
       "2             l1   {'alpha': 0.001, 'penalty': 'l1'}           0.956522   \n",
       "3             l2   {'alpha': 0.001, 'penalty': 'l2'}           0.956522   \n",
       "4             l1    {'alpha': 0.01, 'penalty': 'l1'}           1.000000   \n",
       "5             l2    {'alpha': 0.01, 'penalty': 'l2'}           0.956522   \n",
       "6             l1     {'alpha': 0.1, 'penalty': 'l1'}           0.956522   \n",
       "7             l2     {'alpha': 0.1, 'penalty': 'l2'}           0.956522   \n",
       "8             l1     {'alpha': 1.0, 'penalty': 'l1'}           0.304348   \n",
       "9             l2     {'alpha': 1.0, 'penalty': 'l2'}           0.956522   \n",
       "10            l1     {'alpha': 2.0, 'penalty': 'l1'}           0.304348   \n",
       "11            l2     {'alpha': 2.0, 'penalty': 'l2'}           1.000000   \n",
       "12            l1     {'alpha': 3.0, 'penalty': 'l1'}           0.304348   \n",
       "13            l2     {'alpha': 3.0, 'penalty': 'l2'}           0.956522   \n",
       "14            l1     {'alpha': 4.0, 'penalty': 'l1'}           0.304348   \n",
       "15            l2     {'alpha': 4.0, 'penalty': 'l2'}           0.956522   \n",
       "16            l1     {'alpha': 5.0, 'penalty': 'l1'}           0.304348   \n",
       "17            l2     {'alpha': 5.0, 'penalty': 'l2'}           0.913043   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.956522           0.909091           0.909091   \n",
       "1            0.956522           0.909091           0.909091   \n",
       "2            0.956522           0.909091           0.909091   \n",
       "3            0.956522           0.909091           0.909091   \n",
       "4            0.956522           0.909091           0.909091   \n",
       "5            0.913043           0.909091           0.863636   \n",
       "6            0.956522           0.863636           0.863636   \n",
       "7            0.913043           0.909091           0.818182   \n",
       "8            0.304348           0.318182           0.363636   \n",
       "9            0.956522           0.863636           0.772727   \n",
       "10           0.304348           0.363636           0.363636   \n",
       "11           0.869565           0.727273           0.772727   \n",
       "12           0.304348           0.363636           0.318182   \n",
       "13           0.956522           0.681818           0.727273   \n",
       "14           0.304348           0.318182           0.318182   \n",
       "15           0.826087           0.727273           0.772727   \n",
       "16           0.304348           0.318182           0.318182   \n",
       "17           0.826087           0.727273           0.772727   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.818182         0.909881        0.050519                2  \n",
       "1            0.818182         0.909881        0.050519                2  \n",
       "2            0.818182         0.909881        0.050519                2  \n",
       "3            0.818182         0.909881        0.050519                2  \n",
       "4            0.863636         0.927668        0.046593                1  \n",
       "5            0.818182         0.892095        0.047226                7  \n",
       "6            0.863636         0.900791        0.045504                6  \n",
       "7            0.818182         0.883004        0.055483                8  \n",
       "8            0.363636         0.330830        0.027258               15  \n",
       "9            0.818182         0.873518        0.073618                9  \n",
       "10           0.363636         0.339921        0.029045               14  \n",
       "11           0.818182         0.837549        0.093971               10  \n",
       "12           0.363636         0.330830        0.027258               15  \n",
       "13           0.818182         0.828063        0.113708               11  \n",
       "14           0.318182         0.312648        0.006777               18  \n",
       "15           0.772727         0.811067        0.079176               12  \n",
       "16           0.363636         0.321739        0.021843               17  \n",
       "17           0.772727         0.802372        0.063574               13  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd06da8",
   "metadata": {},
   "source": [
    "The *best_params_* attribute gives the hyperparameters that give the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41acbf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd45fe0",
   "metadata": {},
   "source": [
    "The *best_score_* attribute gives the average cross-validation score.  This should not be confused with the model accuracy.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07f49ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9549407114624507"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c184ab6",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bae40437",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5aa4cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9210526315789473"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5933e8",
   "metadata": {},
   "source": [
    "$\\Box$\n",
    "\n",
    "##### Example 3\n",
    "\n",
    "Put the best params into the classifier in Example 1.\n",
    "\n",
    "Run Example 2 again without constant learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8cfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
